# ğŸ› ï¸ Job Scheduler Microservice

A production-ready job scheduler microservice built with **FastAPI**, allowing users to create, list, and manage scheduled jobs via REST API. Jobs are scheduled using flexible **cron expressions** and executed by a background scheduler.

---

## ğŸš€ Features

- âœ… **Create Jobs** with custom name, description, and schedule
- âœ… **Cron-based Scheduling** using APScheduler
- âœ… **List All Jobs**
- âœ… **Get Job by ID**
- âœ… **Database-backed** (SQLite)
- âœ… **Swagger API Docs** (FastAPI auto-docs)
- âœ… **Modular code** following SOLID principles
- âœ… Designed for **Scalability & Performance**

---

## ğŸ§ª API Endpoints

| Method | Endpoint        | Description                  |
|--------|------------------|------------------------------|
| `POST` | `/jobs`          | Create and schedule a new job |
| `GET`  | `/jobs`          | List all scheduled jobs       |
| `GET`  | `/jobs/{id}`     | Get details of a specific job |

---

## ğŸ“¦ Technologies Used

- FastAPI
- SQLAlchemy
- APScheduler
- SQLite / PostgreSQL
- Pydantic
- Uvicorn

---

## ğŸ–¥ï¸ Running Locally

### 1. Clone the Repo

```bash
git clone https://github.com/your-username/scheduler-service.git
cd scheduler-service
```

### 2. Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Run the App

```bash
uvicorn app.main:app --reload
```

### 5. Open API Docs
Go to ğŸ‘‰ http://127.0.0.1:8000/docs

---

## âš™ï¸ Example Job Payload

```bash
json

{
  "name": "Weekly Report Job",
  "description": "Sends report every Monday",
  "schedule_type": "cron",
  "cron_expression": "0 9 * * MON"
}
```
---

## ğŸŒ Scaling Strategy (For Brownie Points ğŸŒŸ)

To scale this microservice across ~10,000 users, ~1,000 services, and ~6,000 API requests/minute, we recommend:

### âœ… Horizontal Scalability
- Containerize with Docker and deploy multiple instances behind a load balancer (e.g., Kubernetes + NGINX or AWS ALB)
- Use Redis or a distributed store to coordinate scheduled jobs across instances (e.g., APScheduler + RedisJobStore)

### âœ… Background Processing
- Offload job execution to background workers (e.g., Celery + Redis/RabbitMQ)
- Use task queues to handle job spikes and retries gracefully

### âœ… Database & Performance
- Switch from SQLite to PostgreSQL for production
- Use indexes on job.id and next_run for efficient querying
- Add async support with `databases` or `async SQLAlchemy` for high I/O workloads

---

